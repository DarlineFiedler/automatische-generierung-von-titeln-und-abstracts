{ "Pred": ["To predict these scores automatically , features based on reading speed and number of disfluencies were extracted , after an automatic disfluency detection .<q>Various regression models were trained , with Gaussian process regression giving best results for automatic features .<q>A computational tool that assists with recording reading tasks , automatically analyzing them and providing performance metrics could be a significant help .", "These classifiers are tested on utterances from different English speakers in the TIMIT dataset .<q>Nasals and approximants consonants are often confused with each other .<q>The present study uses a spectral representation obtained using the zero time windowing ( ZTW ) analysis of speech , for the task of distinction between these two .", "This also allows us to interpret the weights of the second convolutional layer in the same way as 2D patches learned on critical band energies by typical convolutional neural networks .<q>The evaluation is performed on an English LVCSR task .<q>Trained on the raw time signal , the convolutional layers allow to reduce the WER on the test set from 25.5 % to 23.4 % , compared to an MFCC based result of 22.1 % using fully connected layers .", "We consider the task of speech based automatic classification of patients with amyotrophic lateral sclerosis ( ALS ) and healthy subjects .<q>However , a classifier trained with recordings from all devices together performs more uniformly across all devices .<q>Sustained phoneme production ( PHON ) , diadochokinetic task ( DDK ) and spontaneous speech ( SPON ) have been used as speech tasks .", "In this paper we substitute the waveform generation vocoder of MUSA , our Spanish TTS , with SampleRNN , a neural vocoder which was recently proposed as a deep autoregressive raw waveform generation model .<q>The subjective evaluation shows that the second system outperforms both the original Ahocoder and SampleRNN as an independent neural vocoder .<q>Secondly , the system is trained with the parameters predicted by MUSA , where SampleRNN and MUSA are jointly optimized .", "To improve the robustness to transcription errors , recent solutions propose to map these automatic transcriptions in a latent space .<q>The main drawback of this method is the number of sub-tasks needed to build the c-vector space .<q>Performance of spoken language understanding applications declines when spoken documents are automatically transcribed in noisy conditions due to high Word Error Rates ( WER ) .", "Also , we developed a tagger that facilitates the automatic tagging of the code-switching instances .<q>However , for training the language model ( LM ) for such tasks , a very limited code-switched textual resources are available as yet .<q>Code-switching refers to the phenomena of mixing of words or phrases from foreign languages while communicating in a native language by the multilingual speakers .", "Physical models of the human vocal tract with a moveable tongue have been reported in past literature .<q>In this study , we developed a new model with a flexible tongue .<q>Apart from the tongue , the model is static and solid ; the gel tongue is the main part that can be manipulated .", "Linguistic prosody was accurately matched in all conditions .<q>Matching emotional expressions was excellent for VV , poorer for VA , and near chance for AA and AV presentations .<q>These differences are discussed in terms of the relationship between types of auditory and visual cues and task effects .", "This architecture maps a variable length utterance into a fixed dimensional embedding which retains the relevant sequence level information .<q>This kind of network is starting to outperform the state-of-the-art i-vector embeddings in tasks like speaker and language recognition .<q>This is achieved by a temporal pooling layer .", "Unfortunately , conventional ASR models are not suitable for the low memory setting of on-device speech recognition .<q>) , for which numeric sequences are composed of in-vocabulary numbers , and then using an FST verbalizer to denormalize the result .<q>In the case of the longest numeric sequences , we see reduction of WER by up to a factor of 8 .", "Deep learning is used to estimate the speech presence probability and the update factor of noise statistics , which are then integrated into the Wiener filter-based speech enhancement structure to enhance the desired speech .<q>Noise statistics and speech spectrum characteristics are the essential information for the single channel speech enhancement .<q>Obviously , the hybrid signal processing/deep learning scheme may be a smart alternative .", "Deep Neural Networks ( DNN ) have shown promise in a wide range of machine learning tasks , but for Behavioral Signal Processing ( BSP ) tasks their application has been constrained due to limited quantity of data .<q>We present results on multiple behavior codes in the couples â€™ therapy domain and demonstrate the benefits in behavior classification accuracy .<q>We also show the viability of this system towards live behavior annotations .", "Visual Voice Activity Detection ( V-VAD ) involves the detection of speech activity of a speaker using visual features .<q>In this paper , we propose a speaker independent , real-time solution for V-VAD .<q>Unidirectional LSTMs are used in both the methods to make it online and learn temporal dependence .", "To improve the accuracy of the acoustic model , the progressive deep neural networks ( PDNN ) is applied for acoustic modeling in statistical parametric speech synthesis ( SPSS ) in our method .<q>Both objective and subjective experimental results demonstrate the effectiveness of the proposed technique .<q>And the multi-task learning methods were applied to acoustic modeling with several targets in a global cost function .", "A key step towards building such a system is to define reliable hotspot labels , which will dictate the performance of machine learning algorithms .<q>A system with this capability can have real applications in many domains .<q>This paper also demonstrates that defining those emotionally salient segments using perceptual evaluation is a hard problem resulting in low inter-evaluator agreement .", "Feature selection method is introduced to avoid high variance and overfitting for spoofing detection .<q>In the meanwhile , dimension of the feature is relatively higher than the traditional feature and usually with a higher variance .<q>It has been proven that constant Q cepstral coefficients ( CQCCs ) processes speech in different frequencies with variable resolution and performs much better than traditional features .", "A fake speech signal is generated from a very compressed representation of the glottal excitation using conditional GANs as a deep generative model .<q>Classical parametric speech coding techniques provide a compact representation for speech signals .<q>Moreover , the usage of GANs enables to generate signals in one-shot compared to autoregressive generative models .", "Then we design a CNN-based feature representation using amplitude and phase information .<q>Integrating amplitude spectrogram with phase information , the relative emotion error recognition rates are reduced by over 33 % in comparison with using only amplitude-based feature .<q>Previous studies of speech emotion recognition utilize convolutional neural network ( CNN ) directly on amplitude spectrogram to extract features .", "Singing synthesis is a rising musical art form gaining popularity amongst composers and end-listeners alike .<q>SERAPHIM will be made available as a toolbox on Unity 3D for easy adoption into game development across multiple platforms .<q>SERAPHIM is a wavetable synthesis system that is lightweight and deployable on mobile platforms .", "In this work , we present a novel scheme that incorporates depression severity as a parameter in Deep Neural Networks ( DNNs ) .<q>Despite a wide interest in affect prediction , and several studies linking the effect of depression on affective expressions , only a limited number of affect prediction models account for the depression severity .<q>We also present analysis of the impact of such an alteration in DNNs during training and testing .", "This study proposes a novel Active Feature Transformation ( AFT ) method for automatic recognition of attitudes ( a form of non-verbal behaviour ) in video blogs .<q>The success of a video blog is measured using metrics like the number of views and comments by online viewers .<q>Researchers have highlighted the importance of non-verbal behaviours ( e.g .", "These are naturally-defined objective metrics and are helpful for comparing recognition methods fairly .<q>The latter is close to the averaged correlation between the scores of the human subjects , 0.765 , which suggests that we can predict the human-perceived scores using those features and that we can leverage human perception model for evaluating speech recognition performance .<q>To address this problem , we study and propose a metric which replicates human-annotated scores using their perception to the recognition results .", "Voice quality features performed as well as MFCCs .<q>Automatic assessment of depression from speech signals is affected by variabilities in acoustic content and speakers .<q>Leveraging this unique and extensive database , we built an i-vector framework .", "In the second step , the syllable and phoneme boundaries and labels are inferred hierarchically by using a duration-informed hidden Markov model ( HMM ) .<q>The proposed method is compared with a baseline method based on hidden semi-Markov model ( HSMM ) forced alignment .<q>We propose a two-step method .", "Hidden Markov Models ( HMMs ) have been studied and used extensively in speech and birdsong recognition , but they are not robust to limited training data and noise .<q>For the GMM-HMM framework , the number of states and the mixture components for each state are determined by the acoustic variation of each phrase type .<q>First , the algorithm learns the global Gaussian Mixture Models ( GMMs ) for all training phrases available .", "First experiments with an ASR system trained on the Althingi corpus have been conducted , showing promising results .<q>Word error rate of 16.38 % was obtained using time-delay deep neural network ( TD-DNN ) and 14.76 % was obtained using long-short term memory recurrent neural network ( LSTM-RNN ) architecture .<q>Acoustic data acquisition for under-resourced languages is an important and challenging task .", "For the training data , we used two well-known meeting corpora - the AMI and the ICSI datasets , together with the provided samples from the DIHARD challenge .<q>The second is a simple noise addition with sampled signal-to-noise ratios .<q>All training setups are compared in terms of diarization error rate and mutual information in the evaluation set of the challenge .", "The goal is to provide a speaker with an intuitive visualization of his/her tongue movement , in real-time , and with minimum human intervention .<q>For that purpose , a compact representation of each image is extracted using a PCA-based decomposition technique ( named EigenTongue ) .<q>Artificial neural networks are then used to convert the extracted visual features into control parameters of a PCA-based tongue contour model .", "Overall , the results suggest that picture naming and word reading rely on sensory-motor representations that may be linked to contextual ( or surface ) characteristics .<q>This observation contrasts with recent findings showing an effect of the modality ( a written word vs. a go signal ) on adaptation .<q>In this speech production experiment , speakers â€™ auditory feedback was altered online , inducing adaptation .", "Psychotic disorders are often characterized by two groups of symptoms : negative and positive .<q>Finally , we demonstrate that measures from the Brief Psychiatric Rating Scale ( BPRS ) can be estimated with acoustic descriptors .<q>Our experiments show relationships between psychotic symptoms and acoustic descriptors related to voice quality consistency , variation of speech rate and volume , vowel space , and a parameter of glottal flow .", "For four of the six speakers the measures revealed a trend of tenser phonation on the focal syllable ( an increase in EE and F0 and typically , a decrease in OQ and RD ) as well as increased laxness in the postfocal part of the utterance .<q>This paper describes cross-speaker variation in the voice source correlates of focal accentuation and deaccentuation .<q>For two of the speakers , however , the measurements showed a different trend .", "The speech overlap may be explained and predicted by the dialog context , the linguistic or acoustic descriptors .<q>Overlapping speech is one of the most frequently occurring events in the course of human-human conversations .<q>Understanding the dynamics of overlapping speech is crucial for conversational analysis and for modeling human-machine dialog .", "Speech Enhancement is a challenging and important area of research due to the many applications that depend on improved signal quality .<q>It is a pre-processing step of speech processing systems and used for perceptually improving quality of speech for humans .<q>Experiments are conducted comparing the POS-DAE against the Mean Square Error loss function using speech distortion , noise reduction and Perceptual Evaluation of Speech Quality .", "This behavioral study investigated whether and how the frequency and phase of an entrained rhythm would influence the temporal sampling of subsequent speech .<q>Target words were presented at various phases of the entrained rhythm .<q>These outcomes are compatible with theories suggesting that sensory timing is evaluated relative to entrained frequency .", "One way to counter such difficulties is through user-machine interaction .<q>It is shown to achieve significantly better performance compared with the previous hand-crafted states .<q>User-machine interaction is important for spoken content retrieval .", "Recordings are coarsely synchronized to a common start time .<q>Experimental results show that binary classification accuracy improves from 96.84 % to 97.37 % .<q>Segments of lecture are primarily the speech of the lecturer , while segments of discussion include student speech , silence and noise .", "This paper assesses the use of a non-linear manifold structure with multiple DNNs for phone classification .<q>Phone classification experiments are performed on TIMIT .<q>The results show that using the BPC-dependent DNNs provides small but significant improvements in phone classification accuracy relative to a single global DNN .", "This paper examined the effect of multi-talker babble noise [ 1 ] on lexical tone identification and discrimination in 14 Cantonese-speaking amusics and 14 controls at three levels of signal-to-noise ratio ( SNR ) .<q>It also affects lexical tone perception .<q>Results reveal that the amusics were less accurate in the identification of tones compared to controls in all SNR conditions .", "Example-based speech enhancement is a promising approach for coping with highly non-stationary noise .<q>This paper proposes using bottleneck features ( BNFs ) extracted from a deep neural network ( DNN ) acoustic model for the example search .<q>Experimental results on the Aurora4 corpus show that the example-based approach using BNFs greatly improves the enhanced speech quality compared with that using MFCCs .", "Speech recognition of foreign accented ( non-native or L2 ) speech remains a challenge to the state-of-the-art .<q>We investigate both supervised ( where transcription of the accented data is available ) and unsupervised approaches to using the accented data and associated augmentations .<q>The improvements from training accent specific models with the augmented data are substantial .", "Engagement is an indicator of how much a user is interested in the current dialogue .<q>We propose a two-step engagement recognition where each annotator 's recognition is modeled and the different annotators ' models are aggregated to recognize the integrated label .<q>The proposed neural network consists of two parts ."]}